
By CADE METZMARCH 19, 2018

LIDAR UNIT
CAMERAS
Constantly spinning, it uses laser beams to generate a 360-degree image of the car’s surroundings.
Uses parallax from multiple images to find the distance to various objects. Cameras also detect traffic lights and signs, and help recognize moving objects like pedestrians and bicyclists.
RADAR SENSORS
Measure the distance from the car to obstacles.
ADDITIONAL
LIDAR UNITS
MAIN COMPUTER (LOCATED IN TRUNK)
Analyzes data from the sensors, and compares its stored maps to assess current conditions.
LIDAR UNIT
CAMERAS
Constantly spinning, it uses laser beams to generate a 360-degree image of the car’s surroundings.
Uses parallax from multiple images to find the distance to various objects. Cameras also detect traffic lights and signs, and help recognize moving objects like pedestrians and bicyclists.
RADAR SENSORS
Measure the distance from the car to obstacles.
MAIN COMPUTER
(LOCATED IN TRUNK)
ADDITIONAL
LIDAR UNITS
Analyzes data from the sensors, and compares its stored maps to assess current conditions.
LIDAR UNIT
CAMERAS
Constantly spinning, it uses laser beams to generate a 360-degree image of the car’s surroundings.
Uses parallax from multiple images to find the distance to various objects. Cameras also detect traffic lights and signs, and help recognize moving objects like pedestrians and bicyclists.
RADAR SENSORS
Measure the distance from the car to obstacles.
MAIN COMPUTER
(LOCATED IN TRUNK)
Analyzes data from the sensors, and compares its stored maps to assess current conditions.
ADDITIONAL
LIDAR UNITS
1
2
3
4
5
LIDAR UNIT
1
Constantly spinning, it uses laser beams to generate a 360-degree image of the car’s surroundings.
CAMERAS
2
Uses parallax from multiple images to find the distance to various objects. Cameras also detect traffic lights and signs, and help recognize moving objects like pedestrians and bicyclists.
MAIN COMPUTER (LOCATED IN TRUNK)
3
Analyzes data from the sensors, and compares its stored maps to assess current conditions.
RADAR SENSORS
4
Measure the distance from the car to various obstacles.
ADDITIONAL LIDAR UNITS
5
5
On Sunday night, a woman died after she was hit by a self-driving car operated by Uber in Tempe, Ariz. The car was operating autonomously, though a safety driver was behind the wheel, according to a statement from the local police.
Uber is one of many companies now testing this kind of vehicle in Arizona, California and other parts of the country. Waymo, the self-driving car company owned by Google’s parent company, Alphabet, has said it is also operating autonomous cars on the outskirts of Phoenix without a safety driver behind the wheel. On Monday, Uber said it was halting tests in Tempe, Pittsburgh, Toronto and San Francisco.
Here is a brief guide to the way these cars operate.
When designing these vehicles, companies like Uber and Waymo begin by building a three-dimensional map of a place. They equip ordinary automobiles with lidar sensors — “light detection and ranging” devices that measure distances using pulses of light — and as company workers drive these cars on local roads, these expensive devices collect the information needed to build the map.
Once the map is complete, cars can use it to navigate the roads on their own. As they do, they continue to track their surroundings using lidar, and they compare what they see with what the map shows. In this way, the car gains a good idea of where it is in the world.
Advertisement
Lidar also alerts the cars to nearby objects, including other cars, pedestrians and bicyclists.
Lidar works pretty well, but it can’t do everything. It provides information only about objects that are relatively close, which limits how fast cars can drive. Its measurements are not always sharp enough to distinguish one object from another. And when multiple autonomous vehicles drive the same road, their lidar signals can interfere with one another.
Advertisement
Even in situations where lidar works well, these companies want backup systems in place. So most driverless cars are also equipped with a variety of other sensors.
Cameras, radar and global positioning system antennas, the kind of GPS hardware that tells your smartphone where it is.
With the GPS antennas, companies like Uber and Waymo are providing cars with even more information about where they are in the world. With cameras and radar sensors, they can gather additional information about nearby pedestrians, bicyclists, cars and other objects.
Cameras also provide a way to recognize traffic lights, street signs, road markings and other signals that cars need to take into account.
That is the hard part. Sifting through all that data and responding to it require a system of immense complexity.
In some cases, engineers will write specific rules that define how a car should respond in a particular situation. If a Waymo car detects a red light, for example, it is programmed to stop.

Please verify you're not a robot by clicking the box.
Invalid email address. Please re-enter.
You must select a newsletter to subscribe to.
View all New York Times newsletters.
But a team of engineers could never write rules for every situation a car could encounter. So companies like Waymo and Uber are beginning to rely on “machine learning” systems that can learn behavior by analyzing vast amounts of data describing the country’s roadways.
Waymo now uses a system that learns to identify pedestrians by analyzing thousands of photos that contain people walking or running across or near roads.
Advertisement
It is unclear what happened in Tempe. But these cars are designed so that if one system fails, another will kick in. In all likelihood, the Uber cars used lidar and radar as well as cameras to detect and respond to nearby objects, including pedestrians.
Self-driving cars can have difficulty duplicating the subtle, nonverbal communication that goes on between pedestrians and drivers. An autonomous vehicle, after all, can’t make eye contact with someone at a crosswalk.
“It is still important to realize how hard these problems are,” said Ken Goldberg, a professor at the University of California, Berkeley, who specializes in robotics. “That is the thing that many don’t understand, just because these are things humans do so effortlessly.”
These cars are designed to work at night, when some sensors can operate just as well in the daytime. Some companies even argue that it is easier for these cars to operate at night.
But there are conditions that these cars are still struggling to master. They do not work as well in heavy precipitation. They can have trouble in tunnels and on bridges. And they may have difficulty dealing with heavy traffic.
Follow Cade Metz on twitter: @CadeMetz.
We’re interested in your feedback on this page. Tell us what you think.